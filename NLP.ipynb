{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk.data\n",
    "import gensim\n",
    "from distutils.version import LooseVersion, StrictVersion\n",
    "import os\n",
    "import codecs\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "global word2vec_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource(object):\n",
    "    def _load_raw_data(self,filename, is_train=True):\n",
    "        a = []\n",
    "        b = []\n",
    "        regex = 'train_'\n",
    "        if not is_train:\n",
    "            regex = 'test_'\n",
    "        with open(filename, 'r', encoding=\"utf8\") as file:\n",
    "            for line in file :\n",
    "                if regex in line:\n",
    "                    b.append(a)\n",
    "                    a = [line]\n",
    "                elif line!='\\n':\n",
    "                    a.append(line)       \n",
    "        b.append(a)      \n",
    "        return b[1:]\n",
    "    \n",
    "    def _create_row(self, sample, is_train=True):\n",
    "        d = {}\n",
    "        d['id'] = sample[0].replace('\\n','')\n",
    "        review = \"\"\n",
    "        if is_train:\n",
    "            for clause in sample[1:-1]:\n",
    "                review+= clause.replace('\\n','').strip()\n",
    "            d['label'] = int(sample[-1].replace('\\n',''))          \n",
    "        else:         \n",
    "            for clause in sample[1:]:\n",
    "                review+= clause.replace('\\n','').strip()\n",
    "        d['review'] = review\n",
    "        return d\n",
    "    \n",
    "    \n",
    "    def load_data(self, filename, is_train=True):\n",
    "        raw_data = self._load_raw_data(filename, is_train)\n",
    "        lst = []\n",
    "        for row in raw_data:\n",
    "            lst.append(self._create_row(row, is_train))\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load stopwords\n",
    "stopwords_file = 'vietnamese-stopwords.txt'\n",
    "stopwords = []\n",
    "with open(stopwords_file, 'r', encoding=\"utf8\") as file:\n",
    "    for line in file :\n",
    "        stopwords.append(line.replace('\\n','').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vietnamese_chars = \"[^a-z0-9A-Z_ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯĂẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂưăạảấầẩẫậắằẳẵặẹẻẽềềểỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲỴÝỶỸửữựỳỵỷỹ]\"\n",
    "def review_wordlist(review, remove_stopwords= False):\n",
    "    review_text = str(review)\n",
    "    # 2. Removing non-letter.\n",
    "    review_text = re.sub(vietnamese_chars,\" \",review_text)\n",
    "    # 3. Converting to lower case and splitting\n",
    "    words = review_text.lower().split()\n",
    "    # 4. Optionally remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords)     \n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSource()\n",
    "train_data = pd.DataFrame(ds.load_data('dataset/train.crash'))\n",
    "test_data = pd.DataFrame(ds.load_data('dataset/test.crash', is_train=False))\n",
    "train_data['review'] = train_data['review'].fillna(\"none\")\n",
    "test_data['review'] = test_data['review'].fillna(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Dung dc sp tot cam onshop Đóng gói sản phẩm r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời . Son mịn nhưn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời nhưng k có hộp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>1</td>\n",
       "      <td>\":(( Mình hơi thất vọng 1 chút vì mình đã kỳ v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Lần trước mình mua áo gió màu hồng rất ok mà ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  label                                             review\n",
       "0  train_000000      0  \"Dung dc sp tot cam onshop Đóng gói sản phẩm r...\n",
       "1  train_000001      0  \" Chất lượng sản phẩm tuyệt vời . Son mịn nhưn...\n",
       "2  train_000002      0  \" Chất lượng sản phẩm tuyệt vời nhưng k có hộp...\n",
       "3  train_000003      1  \":(( Mình hơi thất vọng 1 chút vì mình đã kỳ v...\n",
       "4  train_000004      1  \"Lần trước mình mua áo gió màu hồng rất ok mà ..."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def extract_emojis(str):\n",
    "    return [c for c in str if c in emoji.UNICODE_EMOJI]\n",
    "\n",
    "good_df = train_data[train_data['label'] == 0]\n",
    "good_comment = good_df['review'].values\n",
    "good_emoji = []\n",
    "for c in good_comment:\n",
    "      good_emoji += extract_emojis(c)\n",
    "\n",
    "good_emoji = np.unique(np.asarray(good_emoji))\n",
    "\n",
    "\n",
    "bad_df = train_data[train_data['label'] == 1]\n",
    "bad_comment = bad_df['review'].values\n",
    "\n",
    "bad_emoji = []\n",
    "for c in bad_comment:\n",
    "    bad_emoji += extract_emojis(c)\n",
    "\n",
    "bad_emoji = np.unique(np.asarray(bad_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:00:47,010 : INFO : loading projection weights from ./word2vec/wiki.vi.model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:01:04,044 : INFO : loaded (231486, 400) matrix from ./word2vec/wiki.vi.model.bin\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(231486, 400)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = './word2vec/wiki.vi.model.bin'\n",
    "#Load word2vec model\n",
    "if os.path.isfile(model):\n",
    "    print ('Loading word2vec model ...')\n",
    "if LooseVersion(gensim.__version__) >= LooseVersion(\"1.0.1\"):\n",
    "    from gensim.models import KeyedVectors\n",
    "    word2vec_model = KeyedVectors.load_word2vec_format(model, binary=True)\n",
    "else:\n",
    "    from gensim.models import Word2Vec\n",
    "    word2vec_model = Word2Vec.load_word2vec_format(model, binary=True)\n",
    "word2vec_model.wv.syn0.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:01:31,856 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tễu', 0.5424543023109436), ('chuộng', 0.5406407117843628), ('thoòng', 0.5046262741088867), ('chộng', 0.4467487633228302), ('hydrophilic', 0.44052204489707947), ('ðáng', 0.3866061270236969), ('karlspreis', 0.3651212751865387), ('thik', 0.35866597294807434), ('cún', 0.3559001088142395), ('ghi', 0.3471173048019409)]\n",
      "['tễu - 0.5424543023109436', 'chuộng - 0.5406407117843628', 'thoòng - 0.5046262741088867', 'chộng - 0.4467487633228302', 'hydrophilic - 0.44052204489707947', 'ðáng - 0.3866061270236969', 'karlspreis - 0.3651212751865387', 'thik - 0.35866597294807434', 'cún - 0.3559001088142395', 'ghi - 0.3471173048019409']\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "try:\n",
    "    sim_list = word2vec_model.most_similar(\"thích\")\n",
    "    print(sim_list)\n",
    "    #output = word2vec_model.most_similar('u' + '\\\"' + 'A' + '\\\"', topn=5)\n",
    "\n",
    "    for wordsimilar in sim_list:\n",
    "        # output[wordsimilar[0]] = wordsimilar[1]\n",
    "        output.append(wordsimilar[0] + ' - '+ str(wordsimilar[1]))\n",
    "except:\n",
    "    print('except')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average all word vectors in a paragraph\n",
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "def extract_emojis(str):\n",
    "    return [c for c in str if c in emoji.UNICODE_EMOJI]\n",
    "emojis_vocab = []\n",
    "for r in train_data['review']:\n",
    "    emojis_vocab += extract_emojis(r)\n",
    "emojis_vocab = np.unique(np.asarray(emojis_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmojiBowFeatures(reviews,vocab):\n",
    "    bow_emoji_features = []\n",
    "    for r in reviews:\n",
    "        emojis = extract_emojis(r)\n",
    "        bag_vector = np.zeros(len(vocab))\n",
    "        # print(emojis_bow)\n",
    "        for e in emojis_bow:\n",
    "            for i,emojii in enumerate(emojis):\n",
    "                if emojii == e: \n",
    "                    bag_vector[i] += 1\n",
    "        bow_emoji_features.append(bag_vector)\n",
    "    return np.asarray(bow_emoji_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data.review, train_data.label, test_size=0.2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 400\n",
    "clean_train_reviews = []\n",
    "for review in x_train:\n",
    "    clean_train_reviews.append(review_wordlist(review, remove_stopwords=False))\n",
    "bow_train_features = getEmojiBowFeatures(x_train, emojis_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 11260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-107f4df5629d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainDataVecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAvgFeatureVecs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_train_reviews\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-127-55a22da5ecf5>\u001b[0m in \u001b[0;36mgetAvgFeatureVecs\u001b[1;34m(reviews, model, num_features)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Review %d of %d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mreviewFeatureVecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureVecMethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-3a0cc7e3eff1>\u001b[0m in \u001b[0;36mfeatureVecMethod\u001b[1;34m(words, model, num_features)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex2word_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mnwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnwords\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mfeatureVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureVec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Dividing the result by number of words to get average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, entities)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average feature vactors for test set     \n",
    "clean_test_reviews = []\n",
    "for review in x_val:\n",
    "    clean_test_reviews.append(review_wordlist(review))\n",
    "bow_train_features = getEmojiBowFeatures(x_val, emojis_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 4827\n",
      "Review 2000 of 4827\n",
      "Review 3000 of 4827\n",
      "Review 4000 of 4827\n"
     ]
    }
   ],
   "source": [
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(trainDataVecs)\n",
    "forest.fit(pd.DataFrame(trainDataVecs).fillna(0), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = forest.predict(pd.DataFrame(testDataVecs).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288792210482702"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_val, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale',verbose=True)\n",
    "clf.fit(pd.DataFrame(trainDataVecs).fillna(0), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(pd.DataFrame(testDataVecs).fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8713486637663145"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>\"Chưa dùng thử nên chưa biết\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>\" Không đáng tiềnVì ngay đợt sale nên mới mua ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>\"Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>\"Vải đẹp.phom oki luôn.quá ưng\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>\"Chuẩn hàng đóng gói đẹp\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_000005</td>\n",
       "      <td>\" Đóng gói sản phẩm rất đẹp và chắc chắn Shop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_000006</td>\n",
       "      <td>\"Sau khi đọc xong cuốn truyện thì cảm xú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_000007</td>\n",
       "      <td>\"Chỉ cảm ứng khi gần dây điện ổ cắm ko có vật ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_000008</td>\n",
       "      <td>\"Tệ😡 Sản phẩm đứt chỉ tùm lum😡 Rách quá trời c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_000009</td>\n",
       "      <td>\"Shop  Chất lượng sản phẩm rất kém Shop phục v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_000010</td>\n",
       "      <td>\"Ad chỉ em cách chỉnh ngày vs\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_000011</td>\n",
       "      <td>\"Cắm phát nhận luôn\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_000012</td>\n",
       "      <td>\"Chất liệu tốt gói hàng chắc chắn sản phẩm chấ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_000013</td>\n",
       "      <td>\"Da mình là hỗn hợp thiên dầu nhạy cảm  sau kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_000014</td>\n",
       "      <td>\"Dù rep ib hơi chậm nhưng chất lượng sản phẩm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_000015</td>\n",
       "      <td>\"Ban đầu mua về mẫu mã thì đẹp  nhưng không đư...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_000016</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời Chất lượng sản...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_000017</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời. Hàng test ra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_000018</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời 💖Đóng gói sản ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_000019</td>\n",
       "      <td>\"Size hơi nhỏ so với số ký.  Chất lượng sản ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_000020</td>\n",
       "      <td>\"Shop làm việc an tâmcó lòng vs hàng rất tốt....\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_000021</td>\n",
       "      <td>\"Shop chuyên chỉnh giá về 20k và lập nick rác ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_000022</td>\n",
       "      <td>\"Giày cực kì ok.... Lúc đầu mua cũng sợ da bị ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_000023</td>\n",
       "      <td>\"Hơi bị mặn\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_000024</td>\n",
       "      <td>\"Sản phẩm mới mua mà đã mất vân tay.chơi game ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_000025</td>\n",
       "      <td>\"sản phẩm trên hình chỉ là minh họa chứ ngoài ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_000026</td>\n",
       "      <td>\"Yêu dã man luôn í. 5 màu màu nào cũng đẹp ko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_000027</td>\n",
       "      <td>\"Tien nao cua do tam chap nhan dc.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_000028</td>\n",
       "      <td>\"Đồng hồ giống hình..nhỏ nhỏ xinh xinh... Đóng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_000029</td>\n",
       "      <td>\"Phục vụ rất kém! Đã phân loại cho khách thì g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>test_010951</td>\n",
       "      <td>\" Thời gian giao hàng rất nhanh. Lần đầu mua h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>test_010952</td>\n",
       "      <td>\"Gà chưa vàng.gia vị chưa thấm.đặt loại cay mà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>test_010953</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời Đóng gói sản p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>test_010954</td>\n",
       "      <td>\"Sữa tắm không thơm lắm giao hàng nhanh đóng g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>test_010955</td>\n",
       "      <td>\"Mới giao mà nút chai dầu gội đã bị gãy  Chất ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>test_010956</td>\n",
       "      <td>\"Giao hàng nhanh. Shop nhjet tình. Máy thì siê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>test_010957</td>\n",
       "      <td>\" Shop phục vụ nhiệt tình \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>test_010958</td>\n",
       "      <td>\"Sản phẩm bị móp khi vận chuyển nhắn tin shop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>test_010959</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời Đóng gói sản p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>test_010960</td>\n",
       "      <td>\"Cốm ngon tuyệt......\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>test_010961</td>\n",
       "      <td>\"Gói hàng kém\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>test_010962</td>\n",
       "      <td>\"Chuẩn mẫu.  \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10963</th>\n",
       "      <td>test_010963</td>\n",
       "      <td>\"shop lam an k có tâm.đặt đơn 99k thi giao han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10964</th>\n",
       "      <td>test_010964</td>\n",
       "      <td>\"Nhận hàng xong là dùng thử luôn cảm giác ban ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10965</th>\n",
       "      <td>test_010965</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời đúng như hình \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10966</th>\n",
       "      <td>test_010966</td>\n",
       "      <td>\"Ko thơm bằng loại màu hồng mua ở bibomar\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>test_010967</td>\n",
       "      <td>\"Nước giặt không có tem chính hãng nhãn dán lỏ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>test_010968</td>\n",
       "      <td>\"Hôm nay mình xin không hài lòng vs nty shop v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>test_010969</td>\n",
       "      <td>\"Shop gói hàng siêu kĩ ^^\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>test_010970</td>\n",
       "      <td>\"Giao hàng lâu. Sai màu . Nhanh trôi. Hóng mãi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>test_010971</td>\n",
       "      <td>\"Sản phẩm đẹp đúng như hình.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10972</th>\n",
       "      <td>test_010972</td>\n",
       "      <td>\" Chất lượng sản phẩm rất kém. Kh biết tại t x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10973</th>\n",
       "      <td>test_010973</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời Đóng gói sản p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10974</th>\n",
       "      <td>test_010974</td>\n",
       "      <td>\"Shop phục vụ rất tốt. \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>test_010975</td>\n",
       "      <td>\"Bé mặc ko vừa mình muốn đổi size thanks shop\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>\" Thời gian giao hàng rất nhanh.ngon.mà cay qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>\"Sản phẩm hơi cũ\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>\"Sản phẩm chắc chắn nhưng k bóng bằng trong hình\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>\" Chất lượng sản phẩm tuyệt vời có mùi thơm rấ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>\"như quảng cáo. sim rất tốt\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10981 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                             review\n",
       "0      test_000000                      \"Chưa dùng thử nên chưa biết\"\n",
       "1      test_000001  \" Không đáng tiềnVì ngay đợt sale nên mới mua ...\n",
       "2      test_000002  \"Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắ...\n",
       "3      test_000003                    \"Vải đẹp.phom oki luôn.quá ưng\"\n",
       "4      test_000004                          \"Chuẩn hàng đóng gói đẹp\"\n",
       "5      test_000005  \" Đóng gói sản phẩm rất đẹp và chắc chắn Shop ...\n",
       "6      test_000006  \"Sau khi đọc xong cuốn truyện thì cảm xú...\n",
       "7      test_000007  \"Chỉ cảm ứng khi gần dây điện ổ cắm ko có vật ...\n",
       "8      test_000008  \"Tệ😡 Sản phẩm đứt chỉ tùm lum😡 Rách quá trời c...\n",
       "9      test_000009  \"Shop  Chất lượng sản phẩm rất kém Shop phục v...\n",
       "10     test_000010                     \"Ad chỉ em cách chỉnh ngày vs\"\n",
       "11     test_000011                               \"Cắm phát nhận luôn\"\n",
       "12     test_000012  \"Chất liệu tốt gói hàng chắc chắn sản phẩm chấ...\n",
       "13     test_000013  \"Da mình là hỗn hợp thiên dầu nhạy cảm  sau kh...\n",
       "14     test_000014  \"Dù rep ib hơi chậm nhưng chất lượng sản phẩm ...\n",
       "15     test_000015  \"Ban đầu mua về mẫu mã thì đẹp  nhưng không đư...\n",
       "16     test_000016  \" Chất lượng sản phẩm tuyệt vời Chất lượng sản...\n",
       "17     test_000017  \" Chất lượng sản phẩm tuyệt vời. Hàng test ra ...\n",
       "18     test_000018  \" Chất lượng sản phẩm tuyệt vời 💖Đóng gói sản ...\n",
       "19     test_000019  \"Size hơi nhỏ so với số ký.  Chất lượng sản ph...\n",
       "20     test_000020  \"Shop làm việc an tâmcó lòng vs hàng rất tốt....\"\n",
       "21     test_000021  \"Shop chuyên chỉnh giá về 20k và lập nick rác ...\n",
       "22     test_000022  \"Giày cực kì ok.... Lúc đầu mua cũng sợ da bị ...\n",
       "23     test_000023                                       \"Hơi bị mặn\"\n",
       "24     test_000024  \"Sản phẩm mới mua mà đã mất vân tay.chơi game ...\n",
       "25     test_000025  \"sản phẩm trên hình chỉ là minh họa chứ ngoài ...\n",
       "26     test_000026  \"Yêu dã man luôn í. 5 màu màu nào cũng đẹp ko ...\n",
       "27     test_000027                \"Tien nao cua do tam chap nhan dc.\"\n",
       "28     test_000028  \"Đồng hồ giống hình..nhỏ nhỏ xinh xinh... Đóng...\n",
       "29     test_000029  \"Phục vụ rất kém! Đã phân loại cho khách thì g...\n",
       "...            ...                                                ...\n",
       "10951  test_010951  \" Thời gian giao hàng rất nhanh. Lần đầu mua h...\n",
       "10952  test_010952  \"Gà chưa vàng.gia vị chưa thấm.đặt loại cay mà...\n",
       "10953  test_010953  \" Chất lượng sản phẩm tuyệt vời Đóng gói sản p...\n",
       "10954  test_010954  \"Sữa tắm không thơm lắm giao hàng nhanh đóng g...\n",
       "10955  test_010955  \"Mới giao mà nút chai dầu gội đã bị gãy  Chất ...\n",
       "10956  test_010956  \"Giao hàng nhanh. Shop nhjet tình. Máy thì siê...\n",
       "10957  test_010957                        \" Shop phục vụ nhiệt tình \"\n",
       "10958  test_010958  \"Sản phẩm bị móp khi vận chuyển nhắn tin shop ...\n",
       "10959  test_010959  \" Chất lượng sản phẩm tuyệt vời Đóng gói sản p...\n",
       "10960  test_010960                             \"Cốm ngon tuyệt......\"\n",
       "10961  test_010961                                     \"Gói hàng kém\"\n",
       "10962  test_010962                                     \"Chuẩn mẫu.  \"\n",
       "10963  test_010963  \"shop lam an k có tâm.đặt đơn 99k thi giao han...\n",
       "10964  test_010964  \"Nhận hàng xong là dùng thử luôn cảm giác ban ...\n",
       "10965  test_010965  \" Chất lượng sản phẩm tuyệt vời đúng như hình \"\n",
       "10966  test_010966         \"Ko thơm bằng loại màu hồng mua ở bibomar\"\n",
       "10967  test_010967  \"Nước giặt không có tem chính hãng nhãn dán lỏ...\n",
       "10968  test_010968  \"Hôm nay mình xin không hài lòng vs nty shop v...\n",
       "10969  test_010969                         \"Shop gói hàng siêu kĩ ^^\"\n",
       "10970  test_010970  \"Giao hàng lâu. Sai màu . Nhanh trôi. Hóng mãi...\n",
       "10971  test_010971                      \"Sản phẩm đẹp đúng như hình.\"\n",
       "10972  test_010972  \" Chất lượng sản phẩm rất kém. Kh biết tại t x...\n",
       "10973  test_010973  \" Chất lượng sản phẩm tuyệt vời Đóng gói sản p...\n",
       "10974  test_010974                           \"Shop phục vụ rất tốt. \"\n",
       "10975  test_010975     \"Bé mặc ko vừa mình muốn đổi size thanks shop\"\n",
       "10976  test_010976  \" Thời gian giao hàng rất nhanh.ngon.mà cay qu...\n",
       "10977  test_010977                                  \"Sản phẩm hơi cũ\"\n",
       "10978  test_010978  \"Sản phẩm chắc chắn nhưng k bóng bằng trong hình\"\n",
       "10979  test_010979  \" Chất lượng sản phẩm tuyệt vời có mùi thơm rấ...\n",
       "10980  test_010980                       \"như quảng cáo. sim rất tốt\"\n",
       "\n",
       "[10981 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 10981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 10981\n",
      "Review 2000 of 10981\n",
      "Review 3000 of 10981\n",
      "Review 4000 of 10981\n",
      "Review 5000 of 10981\n",
      "Review 6000 of 10981\n",
      "Review 7000 of 10981\n",
      "Review 8000 of 10981\n",
      "Review 9000 of 10981\n",
      "Review 10000 of 10981\n"
     ]
    }
   ],
   "source": [
    "# Calculating average feature vactors for test set     \n",
    "clean_real_test_reviews = []\n",
    "for review in test_data['review']:\n",
    "    clean_real_test_reviews.append(review_wordlist(review))\n",
    "    \n",
    "realTestDataVecs = getAvgFeatureVecs(clean_real_test_reviews, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(pd.DataFrame(realTestDataVecs).fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'] = y_predict\n",
    "test_data[['id','label']].to_csv('predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
