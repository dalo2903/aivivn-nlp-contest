{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource(object):\n",
    "\n",
    "    def _load_raw_data(self,filename, is_train=True):\n",
    "        \n",
    "        a = []\n",
    "        b = []\n",
    "        \n",
    "        regex = 'train_'\n",
    "        if not is_train:\n",
    "            regex = 'test_'\n",
    "        \n",
    "        with open(filename, 'r', encoding=\"utf8\") as file:\n",
    "            for line in file :\n",
    "                if regex in line:\n",
    "                    b.append(a)\n",
    "                    a = [line]\n",
    "                elif line!='\\n':\n",
    "                    a.append(line)\n",
    "                    \n",
    "        b.append(a)      \n",
    "        \n",
    "        return b[1:]\n",
    "    \n",
    "    \n",
    "    def _create_row(self, sample, is_train=True):\n",
    "        \n",
    "        d = {}\n",
    "        d['id'] = sample[0].replace('\\n','')\n",
    "        review = \"\"\n",
    "        \n",
    "        if is_train:\n",
    "            for clause in sample[1:-1]:\n",
    "                review+= clause.replace('\\n','').strip()\n",
    "            d['label'] = int(sample[-1].replace('\\n',''))          \n",
    "        else:         \n",
    "            for clause in sample[1:]:\n",
    "                review+= clause.replace('\\n','').strip()\n",
    "        \n",
    "        d['review'] = review\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    \n",
    "    def load_data(self, filename, is_train=True):\n",
    "        \n",
    "        raw_data = self._load_raw_data(filename, is_train)\n",
    "        lst = []\n",
    "        \n",
    "        for row in raw_data:\n",
    "            lst.append(self._create_row(row, is_train))\n",
    "            \n",
    "        return lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_wordlist(review):\n",
    "    review_text = str(review)\n",
    "    # 2. Removing non-letter.\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    # 3. Converting to lower case and splitting\n",
    "    words = review_text.lower().split()\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSource()\n",
    "train_data = pd.DataFrame(ds.load_data('dataset/train.crash'))\n",
    "test_data = pd.DataFrame(ds.load_data('dataset/test.crash', is_train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Dung dc sp tot cam onshop ƒê√≥ng g√≥i s·∫£n ph·∫©m r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>1</td>\n",
       "      <td>\":(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>1</td>\n",
       "      <td>\"L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_000005</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ ƒëi·ªÅu kh√¥ng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_000006</td>\n",
       "      <td>0</td>\n",
       "      <td>\"ƒê√£ nh·∫≠n ƒëc h√†ng r·∫•t nhanh m·ªõi ƒë·∫∑t bu·ªïi t·ªëi m√†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>\"C√°c si√™u ph·∫©m th·∫•y c·∫•u h√¨nh to√†n t·ª±a t·ª±a nhau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_000008</td>\n",
       "      <td>0</td>\n",
       "      <td>\"H√†ng ship nhanh  ch·∫•t l∆∞·ª£ng t·ªët  t∆∞ v·∫•n nhi·ªát...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_000009</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ƒê·ªìng h·ªì ƒë·∫πp nh∆∞ng 1 c√°i ƒë·ª©t d√¢y  1 c√°i k ch·∫°y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train_000010</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi.y h√¨nh ch·ª•p.ƒë√°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_000011</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Hjhj shop giao h√†ng nhanh qu√°. ƒê·∫πp l·∫Øm ·∫° b√© n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_000012</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"nh√¨n ƒë·∫πp ph·∫øt nh·ªâ..\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train_000013</td>\n",
       "      <td>0</td>\n",
       "      <td>\"ƒê√≥ng g√≥i r·∫•t ƒë·∫πp. Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t t·ªët...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train_000014</td>\n",
       "      <td>0</td>\n",
       "      <td>\"SƒÉn ƒëc v·ªõi gi√° 11k. To·∫πt v·ªùi\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train_000015</td>\n",
       "      <td>0</td>\n",
       "      <td>\"OK r·∫•t h√†i l√≤ng\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train_000016</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Giao thi·∫øu m√¨nh c√°i n√†y r·ªìi shop ∆°i T^T\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_000017</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi t√¥i r·∫•t th√≠ch\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_000018</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Gi√†y ƒë·∫πp l·∫Øm c√≥ ƒëi·ªÅu d√¢y h∆°i ng·∫Øn t√≠ ·∫°¬† Ch·∫•t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_000019</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Y·∫øm v·∫£i ƒë·∫πp nh∆∞ng √≠t m·∫´u ƒë·∫πp\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>train_000020</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>train_000021</td>\n",
       "      <td>1</td>\n",
       "      <td>\"kh√¥ng h√†i l√≤ng s·∫£n ph·∫©m cho l·∫Øm. gi·∫∑t lan ƒë·∫ßu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>train_000022</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Giao h√†ng nhanh, m·∫∑c ƒë·∫πpC√°m ∆°n shop\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>train_000023</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi bao b√¨ cute ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>train_000024</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ƒê·ªìng h·ªì th√¨ ƒë·∫πp th·∫≠t. Nh∆∞ng t·∫°i sao kim l√∫c c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>train_000025</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Giao h√†ng si√™u nhanh.ƒê√≥ng g√≥i c·∫©n th·∫≠n v√† t∆∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train_000026</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"C≈©ng h∆°i b·∫•t ti·ªán xu th·∫ø n√†y e r·∫±ng ƒëa ph·∫±n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>train_000027</td>\n",
       "      <td>1</td>\n",
       "      <td>\"To√†n h√†ng trungkhi mua qu√™n ko coi kƒ©\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>train_000028</td>\n",
       "      <td>0</td>\n",
       "      <td>\" ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn. ƒê∆∞·ª£c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>train_000029</td>\n",
       "      <td>0</td>\n",
       "      <td>\"H√¥m nay chi√™n th·ª≠ c√° h·ªìi, c√° chi√™n ƒÉn ng·ªçt h∆°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16057</th>\n",
       "      <td>train_016057</td>\n",
       "      <td>1</td>\n",
       "      <td>\"L·∫ßn ƒë·∫∑t n√†y t√¥i ch·ªâ nh·∫≠n ƒëc 1 b·ªãch t√£ m√† kh√¥n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16058</th>\n",
       "      <td>train_016058</td>\n",
       "      <td>0</td>\n",
       "      <td>\"K√©o s·ª£i ƒë∆∞·ª£c. ¬†Ch·∫•t l∆∞·ª£ng sp kh√° ok. ¬† ƒê√≥ng g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16059</th>\n",
       "      <td>train_016059</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ƒê·∫∑t m√†u n√†y giao m√†u kia¬†\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16060</th>\n",
       "      <td>train_016060</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Ko th·∫•y c·ªëc s·∫°c ƒë√¢u\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16061</th>\n",
       "      <td>train_016061</td>\n",
       "      <td>1</td>\n",
       "      <td>\"ƒë·∫∑t s·ªë nh·ªè giao s·ªë l·ªõn.ko gi·ªëng m·∫´u\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16062</th>\n",
       "      <td>train_016062</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Vi·ªÅn khƒÉn ƒëo·∫°n n·ªëi tr√¥ng c·ª© ki·ªÉu r√°ch r√°ch :(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16063</th>\n",
       "      <td>train_016063</td>\n",
       "      <td>1</td>\n",
       "      <td>\"S·∫£n ph·∫©m m√¨nh mua ng√†y 4/5 ƒë√£ thanh to√°n nh·∫≠n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16064</th>\n",
       "      <td>train_016064</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Gi·∫ßy m·ªÅm. ƒêi √™m ch√¢n nh∆∞ng h∆°i m√πi nh·ª±a\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16065</th>\n",
       "      <td>train_016065</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Son ƒë·∫πp l·∫Øm ·∫° ‚ù§\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16066</th>\n",
       "      <td>train_016066</td>\n",
       "      <td>0</td>\n",
       "      <td>\" R·∫•t ƒë√°ng ti·ªÅn ¬†Shop l√†m vi·ªác c√≥ tr√°ch nhi·ªám ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16067</th>\n",
       "      <td>train_016067</td>\n",
       "      <td>0</td>\n",
       "      <td>\"S·∫£n ph·∫©m ƒë·∫πp v√† ch·∫Øc ch·∫Øn.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16068</th>\n",
       "      <td>train_016068</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16069</th>\n",
       "      <td>train_016069</td>\n",
       "      <td>0</td>\n",
       "      <td>\"ƒê√≥ng g√≥i s·∫£n ph·∫©m ƒë·∫πp v√† c·∫©n th·∫≠n. Th·ªùi gian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16070</th>\n",
       "      <td>train_016070</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Qu√° t·ªët lu√¥n. Ch·∫Øc ch·∫Øn s·∫Ω mua l·∫°i ^^\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16071</th>\n",
       "      <td>train_016071</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Sp Ok.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16072</th>\n",
       "      <td>train_016072</td>\n",
       "      <td>1</td>\n",
       "      <td>\"y h√¨nh nh∆∞ng son ko l√¨ mau tr√¥i c√≥ m√πi kh√≥ ch·ªãu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16073</th>\n",
       "      <td>train_016073</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Ko gi·ªëng h√†ng\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16074</th>\n",
       "      <td>train_016074</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"·ªì r·∫•t ti·ªán v√† g·ªçn\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>train_016075</td>\n",
       "      <td>1</td>\n",
       "      <td>\"√ÇÃÅm thi biÃ£ h∆∞ k v√¥ ƒëi√™n g∆∞Ãâi ƒë√¥Ãâi thiÃÄ b√¢ÃÅt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16076</th>\n",
       "      <td>train_016076</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng ¬†m√¨nh ko ·ª´ng l·∫Øm nh∆∞ng b√© nh√† m√¨n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>train_016077</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Qu√° ƒë·∫πp so v·ªõi gi√° üòç\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16078</th>\n",
       "      <td>train_016078</td>\n",
       "      <td>1</td>\n",
       "      <td>\" Shop ph·ª•c v·ª• r·∫•t k√©m R·∫•t kh√¥ng ƒë√°ng ti·ªÅn Th·ªù...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>train_016079</td>\n",
       "      <td>0</td>\n",
       "      <td>\"H√†ng ƒë·∫πp h∆°n h√¨nh. Good\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16080</th>\n",
       "      <td>train_016080</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"S·ªë ch·∫•m li√™n quan g√¨ v·ªõi b·ª©c h√¨nh nh·ªè x√≠u th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16081</th>\n",
       "      <td>train_016081</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Ch·ªã ch·ªß t∆∞ v·∫•n nhi·ªát t√¨nh ƒê√≥ng g√≥i s·∫£n ph·∫©m r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>train_016082</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Ch·∫≥ng bi·∫øt l√† Shop c√≥ bi·∫øt ƒë·ªçc hay kh√¥ng mua ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16083</th>\n",
       "      <td>train_016083</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Cu·ªën n√†y m·ªèng. ƒê·ªçc m·ªôt bu·ªïi s√°ng l√† h·∫øt. Th√∫ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16084</th>\n",
       "      <td>train_016084</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Mang √™m ch√¢n. ƒê·∫πp¬†\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16085</th>\n",
       "      <td>train_016085</td>\n",
       "      <td>1</td>\n",
       "      <td>\"T√¥i ƒë√£ nh·∫≠n ƒëc h√†ng.Sau ƒë√¢y l√† v√†i l·ªùi mu·ªën n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>train_016086</td>\n",
       "      <td>1</td>\n",
       "      <td>\"H√¨nh v·∫≠y m√† t√∫i x·∫•u q√° k√©m ch·∫•t lg q√°\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16087 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  label                                             review\n",
       "0      train_000000      0  \"Dung dc sp tot cam onshop ƒê√≥ng g√≥i s·∫£n ph·∫©m r...\n",
       "1      train_000001      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞n...\n",
       "2      train_000002      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp...\n",
       "3      train_000003      1  \":(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v...\n",
       "4      train_000004      1  \"L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ...\n",
       "5      train_000005      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ ƒëi·ªÅu kh√¥ng ...\n",
       "6      train_000006      0  \"ƒê√£ nh·∫≠n ƒëc h√†ng r·∫•t nhanh m·ªõi ƒë·∫∑t bu·ªïi t·ªëi m√†...\n",
       "7      train_000007      1  \"C√°c si√™u ph·∫©m th·∫•y c·∫•u h√¨nh to√†n t·ª±a t·ª±a nhau...\n",
       "8      train_000008      0  \"H√†ng ship nhanh  ch·∫•t l∆∞·ª£ng t·ªët  t∆∞ v·∫•n nhi·ªát...\n",
       "9      train_000009      1  \"ƒê·ªìng h·ªì ƒë·∫πp nh∆∞ng 1 c√°i ƒë·ª©t d√¢y  1 c√°i k ch·∫°y...\n",
       "10     train_000010      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi.y h√¨nh ch·ª•p.ƒë√°...\n",
       "11     train_000011      0  \"Hjhj shop giao h√†ng nhanh qu√°. ƒê·∫πp l·∫Øm ·∫° b√© n...\n",
       "12     train_000012      0                            \"\"nh√¨n ƒë·∫πp ph·∫øt nh·ªâ..\"\"\n",
       "13     train_000013      0  \"ƒê√≥ng g√≥i r·∫•t ƒë·∫πp. Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t t·ªët...\n",
       "14     train_000014      0                     \"SƒÉn ƒëc v·ªõi gi√° 11k. To·∫πt v·ªùi\"\n",
       "15     train_000015      0                                  \"OK r·∫•t h√†i l√≤ng\"\n",
       "16     train_000016      1          \"Giao thi·∫øu m√¨nh c√°i n√†y r·ªìi shop ∆°i T^T\"\n",
       "17     train_000017      0      \"Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi t√¥i r·∫•t th√≠ch\"\n",
       "18     train_000018      0  \"Gi√†y ƒë·∫πp l·∫Øm c√≥ ƒëi·ªÅu d√¢y h∆°i ng·∫Øn t√≠ ·∫°¬† Ch·∫•t ...\n",
       "19     train_000019      0                     \"Y·∫øm v·∫£i ƒë·∫πp nh∆∞ng √≠t m·∫´u ƒë·∫πp\"\n",
       "20     train_000020      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...\n",
       "21     train_000021      1  \"kh√¥ng h√†i l√≤ng s·∫£n ph·∫©m cho l·∫Øm. gi·∫∑t lan ƒë·∫ßu...\n",
       "22     train_000022      0              \"Giao h√†ng nhanh, m·∫∑c ƒë·∫πpC√°m ∆°n shop\"\n",
       "23     train_000023      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi bao b√¨ cute ph...\n",
       "24     train_000024      1  \"ƒê·ªìng h·ªì th√¨ ƒë·∫πp th·∫≠t. Nh∆∞ng t·∫°i sao kim l√∫c c...\n",
       "25     train_000025      0  \"Giao h√†ng si√™u nhanh.ƒê√≥ng g√≥i c·∫©n th·∫≠n v√† t∆∞ ...\n",
       "26     train_000026      1  \"\"C≈©ng h∆°i b·∫•t ti·ªán xu th·∫ø n√†y e r·∫±ng ƒëa ph·∫±n ...\n",
       "27     train_000027      1            \"To√†n h√†ng trungkhi mua qu√™n ko coi kƒ©\"\n",
       "28     train_000028      0  \" ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn. ƒê∆∞·ª£c...\n",
       "29     train_000029      0  \"H√¥m nay chi√™n th·ª≠ c√° h·ªìi, c√° chi√™n ƒÉn ng·ªçt h∆°...\n",
       "...             ...    ...                                                ...\n",
       "16057  train_016057      1  \"L·∫ßn ƒë·∫∑t n√†y t√¥i ch·ªâ nh·∫≠n ƒëc 1 b·ªãch t√£ m√† kh√¥n...\n",
       "16058  train_016058      0  \"K√©o s·ª£i ƒë∆∞·ª£c. ¬†Ch·∫•t l∆∞·ª£ng sp kh√° ok. ¬† ƒê√≥ng g...\n",
       "16059  train_016059      1                        \"ƒê·∫∑t m√†u n√†y giao m√†u kia¬†\"\n",
       "16060  train_016060      1                              \"Ko th·∫•y c·ªëc s·∫°c ƒë√¢u\"\n",
       "16061  train_016061      1              \"ƒë·∫∑t s·ªë nh·ªè giao s·ªë l·ªõn.ko gi·ªëng m·∫´u\"\n",
       "16062  train_016062      1  \"Vi·ªÅn khƒÉn ƒëo·∫°n n·ªëi tr√¥ng c·ª© ki·ªÉu r√°ch r√°ch :(...\n",
       "16063  train_016063      1  \"S·∫£n ph·∫©m m√¨nh mua ng√†y 4/5 ƒë√£ thanh to√°n nh·∫≠n...\n",
       "16064  train_016064      0          \"Gi·∫ßy m·ªÅm. ƒêi √™m ch√¢n nh∆∞ng h∆°i m√πi nh·ª±a\"\n",
       "16065  train_016065      0                                  \"Son ƒë·∫πp l·∫Øm ·∫° ‚ù§\"\n",
       "16066  train_016066      0  \" R·∫•t ƒë√°ng ti·ªÅn ¬†Shop l√†m vi·ªác c√≥ tr√°ch nhi·ªám ...\n",
       "16067  train_016067      0                       \"S·∫£n ph·∫©m ƒë·∫πp v√† ch·∫Øc ch·∫Øn.\"\n",
       "16068  train_016068      0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...\n",
       "16069  train_016069      0  \"ƒê√≥ng g√≥i s·∫£n ph·∫©m ƒë·∫πp v√† c·∫©n th·∫≠n. Th·ªùi gian ...\n",
       "16070  train_016070      0            \"Qu√° t·ªët lu√¥n. Ch·∫Øc ch·∫Øn s·∫Ω mua l·∫°i ^^\"\n",
       "16071  train_016071      0                                           \"Sp Ok.\"\n",
       "16072  train_016072      1  \"y h√¨nh nh∆∞ng son ko l√¨ mau tr√¥i c√≥ m√πi kh√≥ ch·ªãu\"\n",
       "16073  train_016073      1                                    \"Ko gi·ªëng h√†ng\"\n",
       "16074  train_016074      0                              \"\"·ªì r·∫•t ti·ªán v√† g·ªçn\"\"\n",
       "16075  train_016075      1  \"√ÇÃÅm thi biÃ£ h∆∞ k v√¥ ƒëi√™n g∆∞Ãâi ƒë√¥Ãâi thiÃÄ b√¢ÃÅt ...\n",
       "16076  train_016076      0  \" Ch·∫•t l∆∞·ª£ng ¬†m√¨nh ko ·ª´ng l·∫Øm nh∆∞ng b√© nh√† m√¨n...\n",
       "16077  train_016077      0                             \"Qu√° ƒë·∫πp so v·ªõi gi√° üòç\"\n",
       "16078  train_016078      1  \" Shop ph·ª•c v·ª• r·∫•t k√©m R·∫•t kh√¥ng ƒë√°ng ti·ªÅn Th·ªù...\n",
       "16079  train_016079      0                          \"H√†ng ƒë·∫πp h∆°n h√¨nh. Good\"\n",
       "16080  train_016080      1  \"\"S·ªë ch·∫•m li√™n quan g√¨ v·ªõi b·ª©c h√¨nh nh·ªè x√≠u th...\n",
       "16081  train_016081      0  \"Ch·ªã ch·ªß t∆∞ v·∫•n nhi·ªát t√¨nh ƒê√≥ng g√≥i s·∫£n ph·∫©m r...\n",
       "16082  train_016082      1  \"Ch·∫≥ng bi·∫øt l√† Shop c√≥ bi·∫øt ƒë·ªçc hay kh√¥ng mua ...\n",
       "16083  train_016083      1  \"Cu·ªën n√†y m·ªèng. ƒê·ªçc m·ªôt bu·ªïi s√°ng l√† h·∫øt. Th√∫ ...\n",
       "16084  train_016084      0                               \"Mang √™m ch√¢n. ƒê·∫πp¬†\"\n",
       "16085  train_016085      1  \"T√¥i ƒë√£ nh·∫≠n ƒëc h√†ng.Sau ƒë√¢y l√† v√†i l·ªùi mu·ªën n...\n",
       "16086  train_016086      1            \"H√¨nh v·∫≠y m√† t√∫i x·∫•u q√° k√©m ch·∫•t lg q√°\"\n",
       "\n",
       "[16087 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from distutils.version import LooseVersion, StrictVersion\n",
    "import os\n",
    "import codecs\n",
    "global word2vec_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-19 02:05:44,993 : INFO : loading projection weights from ./word2vec/wiki.vi.model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-19 02:05:50,232 : INFO : loaded (231486, 400) matrix from ./word2vec/wiki.vi.model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loose\n"
     ]
    }
   ],
   "source": [
    "model = './word2vec/wiki.vi.model.bin'\n",
    "\n",
    "if os.path.isfile(model):\n",
    "    print ('Loading word2vec model ...')\n",
    "if LooseVersion(gensim.__version__) >= LooseVersion(\"1.0.1\"):\n",
    "    from gensim.models import KeyedVectors\n",
    "    word2vec_model = KeyedVectors.load_word2vec_format(model, binary=True)\n",
    "    print('loose')\n",
    "else:\n",
    "    from gensim.models import Word2Vec\n",
    "    word2vec_model = Word2Vec.load_word2vec_format(model, binary=True)\n",
    "    print('strict')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(231486, 400)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-19 02:05:52,943 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m√®o', 0.660437822341919), ('th·ªè', 0.6416544914245605), ('l·ª£n', 0.5719792246818542), ('s√≥i', 0.5173439979553223), ('c√∫n', 0.4996679723262787), ('ng·ª±a', 0.49387115240097046), ('c·ª´u', 0.4883502721786499), ('g·∫•u', 0.4873932898044586), ('ch·ªìn', 0.48664021492004395), ('d√™', 0.4811408519744873)]\n",
      "['m√®o - 0.660437822341919', 'th·ªè - 0.6416544914245605', 'l·ª£n - 0.5719792246818542', 's√≥i - 0.5173439979553223', 'c√∫n - 0.4996679723262787', 'ng·ª±a - 0.49387115240097046', 'c·ª´u - 0.4883502721786499', 'g·∫•u - 0.4873932898044586', 'ch·ªìn - 0.48664021492004395', 'd√™ - 0.4811408519744873']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sim_list = word2vec_model.most_similar(query)\n",
    "    print(sim_list)\n",
    "    #output = word2vec_model.most_similar('u' + '\\\"' + 'A' + '\\\"', topn=5)\n",
    "    output = []\n",
    "    for wordsimilar in sim_list:\n",
    "        # output[wordsimilar[0]] = wordsimilar[1]\n",
    "        output.append(wordsimilar[0] + ' - '+ str(wordsimilar[1]))\n",
    "except:\n",
    "    print('except')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average all word vectors in a paragraph\n",
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data.review, train_data.label, test_size=0.3,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 11260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 11260\n",
      "Review 2000 of 11260\n",
      "Review 3000 of 11260\n",
      "Review 4000 of 11260\n",
      "Review 5000 of 11260\n",
      "Review 6000 of 11260\n",
      "Review 7000 of 11260\n",
      "Review 8000 of 11260\n",
      "Review 9000 of 11260\n",
      "Review 10000 of 11260\n",
      "Review 11000 of 11260\n"
     ]
    }
   ],
   "source": [
    "num_features = 400\n",
    "clean_train_reviews = []\n",
    "for review in x_train:\n",
    "    clean_train_reviews.append(review_wordlist(review))\n",
    "    \n",
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 4827\n",
      "Review 2000 of 4827\n",
      "Review 3000 of 4827\n",
      "Review 4000 of 4827\n"
     ]
    }
   ],
   "source": [
    "# Calculating average feature vactors for test set     \n",
    "clean_test_reviews = []\n",
    "for review in x_val:\n",
    "    clean_test_reviews.append(review_wordlist(review))\n",
    "    \n",
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07030577, -0.5106581 ,  1.3010975 , ..., -0.6133558 ,\n",
       "        -0.14455178, -0.02068147],\n",
       "       [-0.3468156 ,  0.34537446,  0.58451986, ..., -0.6792826 ,\n",
       "         0.5661435 , -1.1725346 ],\n",
       "       [-0.89693165, -0.22562678,  0.73319334, ...,  0.6456311 ,\n",
       "        -0.4851318 , -0.36625028],\n",
       "       ...,\n",
       "       [-0.2616497 , -0.25497115,  0.87429756, ..., -0.00272737,\n",
       "         0.26674172, -0.16582051],\n",
       "       [ 0.37995565, -0.06219149,  0.5032856 , ..., -0.19829117,\n",
       "         0.10717956, -0.08671689],\n",
       "       [ 0.2505056 , -0.19075295,  1.4641299 , ...,  0.09442744,\n",
       "        -0.29018992, -0.15566795]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(trainDataVecs))\n",
    "np.any(np.isnan(trainDataVecs))\n",
    "df = pd.DataFrame(trainDataVecs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = forest.predict(pd.DataFrame(testDataVecs).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681789931634556"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_val, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale',verbose=True)\n",
    "clf.fit(df, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(pd.DataFrame(testDataVecs).fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7973896830329397"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>\"Ch∆∞a d√πng th·ª≠ n√™n ch∆∞a bi·∫øt\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>\" Kh√¥ng ƒë√°ng ti·ªÅnV√¨ ngay ƒë·ª£t sale n√™n m·ªõi mua ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>\"C√°m ∆°n shop. ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>\"V·∫£i ƒë·∫πp.phom oki lu√¥n.qu√° ∆∞ng\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>\"Chu·∫©n h√†ng ƒë√≥ng g√≥i ƒë·∫πp\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_000005</td>\n",
       "      <td>\" ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn Shop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_000006</td>\n",
       "      <td>\"Sau khi ƒëoÃ£c xong cu√¥ÃÅn truy√™Ã£n thiÃÄ caÃâm xuÃÅ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_000007</td>\n",
       "      <td>\"Ch·ªâ c·∫£m ·ª©ng khi g·∫ßn d√¢y ƒëi·ªán ·ªï c·∫Øm ko c√≥ v·∫≠t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_000008</td>\n",
       "      <td>\"T·ªáüò° S·∫£n ph·∫©m ƒë·ª©t ch·ªâ t√πm lumüò° R√°ch qu√° tr·ªùi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_000009</td>\n",
       "      <td>\"Shop  Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t k√©m Shop ph·ª•c v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_000010</td>\n",
       "      <td>\"Ad ch·ªâ em c√°ch ch·ªânh ng√†y vs\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_000011</td>\n",
       "      <td>\"C·∫Øm ph√°t nh·∫≠n lu√¥n\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_000012</td>\n",
       "      <td>\"Ch·∫•t li·ªáu t·ªët g√≥i h√†ng ch·∫Øc ch·∫Øn s·∫£n ph·∫©m ch·∫•...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_000013</td>\n",
       "      <td>\"Da m√¨nh l√† h·ªón h·ª£p thi√™n d·∫ßu nh·∫°y c·∫£m ¬†sau kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_000014</td>\n",
       "      <td>\"D√π rep ib h∆°i ch·∫≠m nh∆∞ng ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_000015</td>\n",
       "      <td>\"Ban ƒë·∫ßu mua v·ªÅ m·∫´u m√£ th√¨ ƒë·∫πp  nh∆∞ng kh√¥ng ƒë∆∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_000016</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi Ch·∫•t l∆∞·ª£ng s·∫£n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_000017</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi. H√†ng test ra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_000018</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi üíñƒê√≥ng g√≥i s·∫£n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_000019</td>\n",
       "      <td>\"Size h∆°i nh·ªè so v·ªõi s·ªë k√Ω.¬† Ch·∫•t l∆∞·ª£ng s·∫£n ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_000020</td>\n",
       "      <td>\"Shop l√†m vi·ªác an t√¢mc√≥ l√≤ng vs h√†ng r·∫•t t·ªët....\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_000021</td>\n",
       "      <td>\"Shop chuy√™n ch·ªânh gi√° v·ªÅ 20k v√† l·∫≠p nick r√°c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_000022</td>\n",
       "      <td>\"Gi√†y c·ª±c k√¨ ok.... L√∫c ƒë·∫ßu mua c≈©ng s·ª£ da b·ªã ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_000023</td>\n",
       "      <td>\"H∆°i b·ªã m·∫∑n\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_000024</td>\n",
       "      <td>\"S·∫£n ph·∫©m m·ªõi mua m√† ƒë√£ m·∫•t v√¢n tay.ch∆°i game ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_000025</td>\n",
       "      <td>\"s·∫£n ph·∫©m tr√™n h√¨nh ch·ªâ l√† minh h·ªça ch·ª© ngo√†i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_000026</td>\n",
       "      <td>\"Y√™u d√£ man lu√¥n √≠. 5 m√†u m√†u n√†o c≈©ng ƒë·∫πp ko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_000027</td>\n",
       "      <td>\"Tien nao cua do tam chap nhan dc.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_000028</td>\n",
       "      <td>\"ƒê·ªìng h·ªì gi·ªëng h√¨nh..nh·ªè nh·ªè xinh xinh... ƒê√≥ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_000029</td>\n",
       "      <td>\"Ph·ª•c v·ª• r·∫•t k√©m! ƒê√£ ph√¢n lo·∫°i cho kh√°ch th√¨ g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>test_010951</td>\n",
       "      <td>\" Th·ªùi gian giao h√†ng r·∫•t nhanh. L·∫ßn ƒë·∫ßu mua h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>test_010952</td>\n",
       "      <td>\"G√† ch∆∞a v√†ng.gia v·ªã ch∆∞a th·∫•m.ƒë·∫∑t lo·∫°i cay m√†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>test_010953</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>test_010954</td>\n",
       "      <td>\"S·ªØa t·∫Øm kh√¥ng th∆°m l·∫Øm giao h√†ng nhanh ƒë√≥ng g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>test_010955</td>\n",
       "      <td>\"M·ªõi giao m√† n√∫t chai d·∫ßu g·ªôi ƒë√£ b·ªã g√£y¬† Ch·∫•t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>test_010956</td>\n",
       "      <td>\"Giao h√†ng nhanh. Shop nhjet t√¨nh. M√°y th√¨ si√™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>test_010957</td>\n",
       "      <td>\" Shop ph·ª•c v·ª• nhi·ªát t√¨nh \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>test_010958</td>\n",
       "      <td>\"S·∫£n ph·∫©m b·ªã m√≥p khi v·∫≠n chuy·ªÉn nh·∫Øn tin shop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>test_010959</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>test_010960</td>\n",
       "      <td>\"C·ªëm ngon tuy·ªát......\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>test_010961</td>\n",
       "      <td>\"G√≥i h√†ng k√©m\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>test_010962</td>\n",
       "      <td>\"Chu·∫©n m·∫´u.  \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10963</th>\n",
       "      <td>test_010963</td>\n",
       "      <td>\"shop lam an k c√≥ t√¢m.ƒë·∫∑t ƒë∆°n 99k thi giao han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10964</th>\n",
       "      <td>test_010964</td>\n",
       "      <td>\"Nh·∫≠n h√†ng xong l√† d√πng th·ª≠ lu√¥n c·∫£m gi√°c ban ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10965</th>\n",
       "      <td>test_010965</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒëuÃÅng nh∆∞ hiÃÄnh \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10966</th>\n",
       "      <td>test_010966</td>\n",
       "      <td>\"Ko th∆°m b·∫±ng lo·∫°i m√†u h·ªìng mua ·ªü bibomar\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>test_010967</td>\n",
       "      <td>\"N∆∞·ªõc gi·∫∑t kh√¥ng c√≥ tem ch√≠nh h√£ng nh√£n d√°n l·ªè...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>test_010968</td>\n",
       "      <td>\"H√¥m nay m√¨nh xin kh√¥ng h√†i l√≤ng vs nty shop v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>test_010969</td>\n",
       "      <td>\"Shop g√≥i h√†ng si√™u kƒ© ^^\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>test_010970</td>\n",
       "      <td>\"Giao h√†ng l√¢u. Sai m√†u . Nhanh tr√¥i. H√≥ng m√£i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>test_010971</td>\n",
       "      <td>\"S·∫£n ph·∫©m ƒë·∫πp ƒë√∫ng nh∆∞ h√¨nh.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10972</th>\n",
       "      <td>test_010972</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t k√©m. Kh bi·∫øt t·∫°i t x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10973</th>\n",
       "      <td>test_010973</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10974</th>\n",
       "      <td>test_010974</td>\n",
       "      <td>\"Shop ph·ª•c v·ª• r·∫•t t·ªët. \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>test_010975</td>\n",
       "      <td>\"B√© m·∫∑c ko v·ª´a m√¨nh mu·ªën ƒë·ªïi size thanks shop\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>\" Th·ªùi gian giao h√†ng r·∫•t nhanh.ngon.m√† cay qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>\"S·∫£n ph·∫©m h∆°i c≈©\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>\"S·∫£n ph·∫©m ch·∫Øc ch·∫Øn nh∆∞ng k b√≥ng b·∫±ng trong h√¨nh\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ m√πi th∆°m r·∫•...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>\"nh∆∞ qu·∫£ng c√°o. sim r·∫•t t·ªët\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10981 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                             review\n",
       "0      test_000000                      \"Ch∆∞a d√πng th·ª≠ n√™n ch∆∞a bi·∫øt\"\n",
       "1      test_000001  \" Kh√¥ng ƒë√°ng ti·ªÅnV√¨ ngay ƒë·ª£t sale n√™n m·ªõi mua ...\n",
       "2      test_000002  \"C√°m ∆°n shop. ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Ø...\n",
       "3      test_000003                    \"V·∫£i ƒë·∫πp.phom oki lu√¥n.qu√° ∆∞ng\"\n",
       "4      test_000004                          \"Chu·∫©n h√†ng ƒë√≥ng g√≥i ƒë·∫πp\"\n",
       "5      test_000005  \" ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn Shop ...\n",
       "6      test_000006  \"Sau khi ƒëoÃ£c xong cu√¥ÃÅn truy√™Ã£n thiÃÄ caÃâm xuÃÅ...\n",
       "7      test_000007  \"Ch·ªâ c·∫£m ·ª©ng khi g·∫ßn d√¢y ƒëi·ªán ·ªï c·∫Øm ko c√≥ v·∫≠t ...\n",
       "8      test_000008  \"T·ªáüò° S·∫£n ph·∫©m ƒë·ª©t ch·ªâ t√πm lumüò° R√°ch qu√° tr·ªùi c...\n",
       "9      test_000009  \"Shop  Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t k√©m Shop ph·ª•c v...\n",
       "10     test_000010                     \"Ad ch·ªâ em c√°ch ch·ªânh ng√†y vs\"\n",
       "11     test_000011                               \"C·∫Øm ph√°t nh·∫≠n lu√¥n\"\n",
       "12     test_000012  \"Ch·∫•t li·ªáu t·ªët g√≥i h√†ng ch·∫Øc ch·∫Øn s·∫£n ph·∫©m ch·∫•...\n",
       "13     test_000013  \"Da m√¨nh l√† h·ªón h·ª£p thi√™n d·∫ßu nh·∫°y c·∫£m ¬†sau kh...\n",
       "14     test_000014  \"D√π rep ib h∆°i ch·∫≠m nh∆∞ng ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m ...\n",
       "15     test_000015  \"Ban ƒë·∫ßu mua v·ªÅ m·∫´u m√£ th√¨ ƒë·∫πp  nh∆∞ng kh√¥ng ƒë∆∞...\n",
       "16     test_000016  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi Ch·∫•t l∆∞·ª£ng s·∫£n...\n",
       "17     test_000017  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi. H√†ng test ra ...\n",
       "18     test_000018  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi üíñƒê√≥ng g√≥i s·∫£n ...\n",
       "19     test_000019  \"Size h∆°i nh·ªè so v·ªõi s·ªë k√Ω.¬† Ch·∫•t l∆∞·ª£ng s·∫£n ph...\n",
       "20     test_000020  \"Shop l√†m vi·ªác an t√¢mc√≥ l√≤ng vs h√†ng r·∫•t t·ªët....\"\n",
       "21     test_000021  \"Shop chuy√™n ch·ªânh gi√° v·ªÅ 20k v√† l·∫≠p nick r√°c ...\n",
       "22     test_000022  \"Gi√†y c·ª±c k√¨ ok.... L√∫c ƒë·∫ßu mua c≈©ng s·ª£ da b·ªã ...\n",
       "23     test_000023                                       \"H∆°i b·ªã m·∫∑n\"\n",
       "24     test_000024  \"S·∫£n ph·∫©m m·ªõi mua m√† ƒë√£ m·∫•t v√¢n tay.ch∆°i game ...\n",
       "25     test_000025  \"s·∫£n ph·∫©m tr√™n h√¨nh ch·ªâ l√† minh h·ªça ch·ª© ngo√†i ...\n",
       "26     test_000026  \"Y√™u d√£ man lu√¥n √≠. 5 m√†u m√†u n√†o c≈©ng ƒë·∫πp ko ...\n",
       "27     test_000027                \"Tien nao cua do tam chap nhan dc.\"\n",
       "28     test_000028  \"ƒê·ªìng h·ªì gi·ªëng h√¨nh..nh·ªè nh·ªè xinh xinh... ƒê√≥ng...\n",
       "29     test_000029  \"Ph·ª•c v·ª• r·∫•t k√©m! ƒê√£ ph√¢n lo·∫°i cho kh√°ch th√¨ g...\n",
       "...            ...                                                ...\n",
       "10951  test_010951  \" Th·ªùi gian giao h√†ng r·∫•t nhanh. L·∫ßn ƒë·∫ßu mua h...\n",
       "10952  test_010952  \"G√† ch∆∞a v√†ng.gia v·ªã ch∆∞a th·∫•m.ƒë·∫∑t lo·∫°i cay m√†...\n",
       "10953  test_010953  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...\n",
       "10954  test_010954  \"S·ªØa t·∫Øm kh√¥ng th∆°m l·∫Øm giao h√†ng nhanh ƒë√≥ng g...\n",
       "10955  test_010955  \"M·ªõi giao m√† n√∫t chai d·∫ßu g·ªôi ƒë√£ b·ªã g√£y¬† Ch·∫•t ...\n",
       "10956  test_010956  \"Giao h√†ng nhanh. Shop nhjet t√¨nh. M√°y th√¨ si√™...\n",
       "10957  test_010957                        \" Shop ph·ª•c v·ª• nhi·ªát t√¨nh \"\n",
       "10958  test_010958  \"S·∫£n ph·∫©m b·ªã m√≥p khi v·∫≠n chuy·ªÉn nh·∫Øn tin shop ...\n",
       "10959  test_010959  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...\n",
       "10960  test_010960                             \"C·ªëm ngon tuy·ªát......\"\n",
       "10961  test_010961                                     \"G√≥i h√†ng k√©m\"\n",
       "10962  test_010962                                     \"Chu·∫©n m·∫´u.  \"\n",
       "10963  test_010963  \"shop lam an k c√≥ t√¢m.ƒë·∫∑t ƒë∆°n 99k thi giao han...\n",
       "10964  test_010964  \"Nh·∫≠n h√†ng xong l√† d√πng th·ª≠ lu√¥n c·∫£m gi√°c ban ...\n",
       "10965  test_010965  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒëuÃÅng nh∆∞ hiÃÄnh \"\n",
       "10966  test_010966         \"Ko th∆°m b·∫±ng lo·∫°i m√†u h·ªìng mua ·ªü bibomar\"\n",
       "10967  test_010967  \"N∆∞·ªõc gi·∫∑t kh√¥ng c√≥ tem ch√≠nh h√£ng nh√£n d√°n l·ªè...\n",
       "10968  test_010968  \"H√¥m nay m√¨nh xin kh√¥ng h√†i l√≤ng vs nty shop v...\n",
       "10969  test_010969                         \"Shop g√≥i h√†ng si√™u kƒ© ^^\"\n",
       "10970  test_010970  \"Giao h√†ng l√¢u. Sai m√†u . Nhanh tr√¥i. H√≥ng m√£i...\n",
       "10971  test_010971                      \"S·∫£n ph·∫©m ƒë·∫πp ƒë√∫ng nh∆∞ h√¨nh.\"\n",
       "10972  test_010972  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t k√©m. Kh bi·∫øt t·∫°i t x...\n",
       "10973  test_010973  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n p...\n",
       "10974  test_010974                           \"Shop ph·ª•c v·ª• r·∫•t t·ªët. \"\n",
       "10975  test_010975     \"B√© m·∫∑c ko v·ª´a m√¨nh mu·ªën ƒë·ªïi size thanks shop\"\n",
       "10976  test_010976  \" Th·ªùi gian giao h√†ng r·∫•t nhanh.ngon.m√† cay qu...\n",
       "10977  test_010977                                  \"S·∫£n ph·∫©m h∆°i c≈©\"\n",
       "10978  test_010978  \"S·∫£n ph·∫©m ch·∫Øc ch·∫Øn nh∆∞ng k b√≥ng b·∫±ng trong h√¨nh\"\n",
       "10979  test_010979  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ m√πi th∆°m r·∫•...\n",
       "10980  test_010980                       \"nh∆∞ qu·∫£ng c√°o. sim r·∫•t t·ªët\"\n",
       "\n",
       "[10981 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 10981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 10981\n",
      "Review 2000 of 10981\n",
      "Review 3000 of 10981\n",
      "Review 4000 of 10981\n",
      "Review 5000 of 10981\n",
      "Review 6000 of 10981\n",
      "Review 7000 of 10981\n",
      "Review 8000 of 10981\n",
      "Review 9000 of 10981\n",
      "Review 10000 of 10981\n"
     ]
    }
   ],
   "source": [
    "# Calculating average feature vactors for test set     \n",
    "clean_test_reviews = []\n",
    "for review in test_data['review']:\n",
    "    clean_test_reviews.append(review_wordlist(review))\n",
    "    \n",
    "realTestDataVecs = getAvgFeatureVecs(clean_test_reviews, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(pd.DataFrame(realTestDataVecs).fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'] = y_predict\n",
    "test_data[['id','label']].to_csv('sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
